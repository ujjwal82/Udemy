}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(formula = lm_formula, data = training_data)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
colIndx <- ncol(test_data)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
colIndx <- ncol(test_data)
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
# classifier <- randomForest(formula = lm_formula, data = training_data)
classifier <- randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 10)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
colIndx <- ncol(test_data)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
colIndx <- ncol(test_data)
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
colIndx <- ncol(test_data)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 10)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'svm')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
colIndx <- ncol(test_data)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 10)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
# model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
# model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
# model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
# model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'svm')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
colIndx <- ncol(test_data)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 10)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
# model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
# model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
# model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
# model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
colIndx <- ncol(test_data)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 500)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
# model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
# model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
# model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
# model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
return(model)
}
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
###
# Function declaration
###
my_model <- function(training_data, test_data, dependent_var, model_name){
colIndx <- ncol(test_data)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_data)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_data)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_data, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 500)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_data[, -colIndx], test = test_data[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_data)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_data[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
# model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
# model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
# model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
# model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
rownames(model) <- c(model_name)
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
Comp_results <<- rbind(Comp_results, model)
return(model)
}
###
# Lets create a dataframe to compare the sentiments across the speeches
###
Comp_results <- data.frame(accuracy = double(),
Recall = double(),
Precision = double(),
F1Score = double(),
G_measure = double()
)
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'svm')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'nb')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'dt')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'rf')
my_model(training_data = training_set, test_data = test_set, dependent_var = 'Liked', model_name = 'knn')
Comp_results
Comp_results
###
# Function declaration
###
my_model <- function(model_name){
colIndx <- ncol(test_set)
lm_formula <- as.formula(paste(dependent_var, ' ~ .', sep = ''))
if(model_name == 'svm'){
# Fitting SVM model on training set
library(e1071)
classifier <- svm(formula = lm_formula, data = training_set)
}
if(model_name == 'nb'){
# Fitting Naive Bayes model on training set
classifier <- naiveBayes(formula = lm_formula, data = training_set)
}
if(model_name == 'dt'){
# Fitting Decision Tree model on training set
library(party)
classifier <- ctree(formula = lm_formula, data = training_set, controls = ctree_control(mincriterion = 0.9, minsplit = 458))
}
if(model_name == 'rf'){
# Fitting Random FOrest model on training set
library(randomForest)
classifier <- randomForest(x = training_set[-colIndx],
y = training_set$Liked,
ntree = 500)
}
if(model_name == 'knn'){
# Fitting K-NN to the Training set and predicting the Test set results
#install.packages("class")
library(class)
y_pred <- knn(train = training_set[, -colIndx], test = test_set[, -colIndx],
cl = training_set[, colIndx], k = 5)
}
# Predicting the test set results
if(model_name != 'knn'){
y_pred <- predict(classifier, newdata = test_set)
}
###
# Let's caculate different parameters, which
# may be used to compare the models
###
# Confussion matrix
cm <- table(test_set[, colIndx], y_pred)
# Calculate other parameters for the model
model <- as.data.frame(0)
model$accuracy <- (sum(diag(cm))/sum(cm))*100
# model$TPR <- (cm[1] / (cm[1] + cm[2]))*100
# model$FPR <- (cm[2] / (cm[1] + cm[2]))*100
# model$FNR <- (cm[3] / (cm[3] + cm[4]))*100
# model$TNR <- (cm[4] / (cm[3] + cm[4]))*100
rownames(model) <- c(model_name)
model$Recall <- cm[1]/ (cm[1]+cm[3])
model$Precision <- cm[1]/ (cm[1]+cm[2])
model$F1Score <- 2*((model$Recall* model$Precision)/(model$Recall + model$Precision))
model$G_measure <- sqrt(model$Recall*model$Precision)
Comp_results <<- rbind(Comp_results, model)
return(model)
}
###
# Let's create a dataframe to compare the results from
# different classification models
###
Comp_results <- data.frame(accuracy = double(),
Recall = double(),
Precision = double(),
F1Score = double(),
G_measure = double()
)
dependent_var = 'Liked'
my_model(model_name = 'svm')
my_model(model_name = 'nb')
my_model(model_name = 'nb')
my_model(model_name = 'dt')
my_model(model_name = 'rf')
my_model(model_name = 'knn')
Comp_results
source('D:/ujjwal/Tutorial/Udemy/Machine Learning A-Z Template Folder/Part 7 - Natural Language Processing/Section 36 - Natural Language Processing/Practice/natural_language_processing.R')
Comp_results
