# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
dataset <- subset(dataset, rownames(dataset) != 'Hawaii')
dataset <- subset(dataset, rownames(dataset) != 'South Carolina')
dataset <- subset(dataset, rownames(dataset) != 'Maine')
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
itemToRemove <- ''
plt_adjR_squares <- numeric(0)
plt_lm_formula <- character(0)
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste("mpg ~ ", paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste("mpg ~ ", paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
###
# Create local copy of the dataset
###
#dataset <- as.data.frame(mtcars)
dataset <-as.data.frame(state.x77)
###
# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
dataset <- subset(dataset, rownames(dataset) != 'Hawaii')
dataset <- subset(dataset, rownames(dataset) != 'South Carolina')
dataset <- subset(dataset, rownames(dataset) != 'Maine')
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
itemToRemove <- ''
plt_adjR_squares <- numeric(0)
plt_lm_formula <- character(0)
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
max(plt_adjR_squares)
# Plot the Adjusted R-squared
plot(plt_adjR_squares, type="b", col="blue",
ylim = range(min(plt_adjR_squares) - 0.05, 0.95),
axes = FALSE, ann= FALSE)
# Make x axis using Mon-Fri labels
axis(1, at=1:length(plt_adjR_squares), lab=F)
text(axTicks(1), y= 0, srt=45, adj=1,
labels=plt_adjR_squares,
xpd=T, cex=1)
# Plot y axis with smaller horizontal labels
axis(2, las=1, cex.axis=0.8)
# Create box around plot
box()
# Create a title with a red, bold/italic font
title(main="Linear Regression (Best model)", col.main="red", font.main=4)
# Label the x and y axes with dark green text
title(xlab="Formula", col.lab=rgb(0,0.5,0))
title(ylab="R-Squared", col.lab=rgb(0,0.5,0))
max(plt_adjR_squares)
###
# Create local copy of the dataset
###
#dataset <- as.data.frame(mtcars)
dataset <-as.data.frame(state.x77)
###
# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
dataset <- subset(dataset, rownames(dataset) != 'Hawaii')
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
itemToRemove <- ''
plt_adjR_squares <- numeric(0)
plt_lm_formula <- character(0)
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
max(plt_adjR_squares)
###
# Create local copy of the dataset
###
#dataset <- as.data.frame(mtcars)
dataset <-as.data.frame(state.x77)
###
# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
itemToRemove <- ''
plt_adjR_squares <- numeric(0)
plt_lm_formula <- character(0)
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
max(plt_adjR_squares)
rownames(dataset)
###
# Create local copy of the dataset
###
#dataset <- as.data.frame(mtcars)
dataset <-as.data.frame(state.x77)
###
# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
dataset <- subset(dataset, rownames(dataset) != 'South Carolina')
dataset <- subset(dataset, rownames(dataset) != 'Hawaii')
dataset <- subset(dataset, rownames(dataset) != 'Maine')
regressor
dataset
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
cars
summary(cars)
regressor <- lm(formula = dist ~ speed, data = cars)
summary(regressor)
y_pred <- predict(regressor,newdata =cars)
y_pred
# see the predidcted values and actual values and compare
data.frame(cbind(y_pred, cars$dist))
###
# Now since we have the best Linear Regression model
# Let's apply that and do predictions.
###
lm_formula <- plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
summary(regressor)
max(plt_adjR_squares)
# we have the best LR model with following formula and Adjusted R-Squared value
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
max(plt_adjR_squares)
plt_adjR_squares
###
# Now since we have the best Linear Regression model
# Let's apply that and do predictions.
###
lm_formula <- plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
regressor <- lm(formula = lm_formula, data = dataset)
summary(regressor)
plt_lm_formula
###
# Create local copy of the dataset
###
#dataset <- as.data.frame(mtcars)
dataset <-as.data.frame(state.x77)
###
# Remove the spaces if any in the column names
###
colnames(dataset) <- gsub(" ", "", colnames(dataset), fixed = TRUE)
# This might change depending on what dataset we are working on.
dependent_var <- 'LifeExp'
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''), '.'))
###
# Create Linear Regerssion model for all the independent variables
###
regressor <- lm(formula = lm_formula, data = dataset)
dataset <- subset(dataset, rownames(dataset) != 'Hawaii')
dataset <- subset(dataset, rownames(dataset) != 'South Carolina')
dataset <- subset(dataset, rownames(dataset) != 'Maine')
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
itemToRemove <- dependent_var
itemToRemove
plt_adjR_squares <- numeric(0)
plt_lm_formula <- character(0)
###
# Let apply a while loop to iterate throught the list of clumns and find out
# the best model for independent variables.
# in every iteration our dependent variable will be mpg
###
factors <- colnames(dataset)
while (length(factors) > 2) {
factors <- factors[!factors == itemToRemove]
lm_formula <- as.formula(paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
plt_lm_formula <- c(plt_lm_formula, paste(paste(dependent_var, ' ~', sep = ''),
paste(factors, collapse=" + ", sep = '')))
regressor <- lm(formula = lm_formula, data = as.data.frame(dataset))
sum_reg <- summary(regressor)
plt_adjR_squares <- c(plt_adjR_squares, sum_reg$adj.r.squared)
# find out what all you can get from Summary()
itemToRemove <- rownames(sum_reg$coefficients)[apply(sum_reg$coefficients , 2, which.max)[4]]
}
# we have the best LR model with following formula and Adjusted R-Squared value
plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
max(plt_adjR_squares)
###
# Now since we have the best Linear Regression model
# Let's apply that and do predictions.
###
lm_formula <- plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
regressor <- lm(formula = lm_formula, data = dataset)
summary(regressor)
y_pred <- predict(regressor,newdata = dataset)
y_pred
# see the predidcted values and actual values and compare
data.frame(cbind(y_pred, dataset$LifeExp))
# see the predidcted values and actual values and compare
data.frame(cbind(y_pred, dataset["LifeExp"]))
# see the predidcted values and actual values and compare
data.frame(cbind(y_pred, dataset[dependent_var]))
# see the predidcted values and actual values and compare
df <- data.frame(cbind(y_pred, dataset[dependent_var]))
colnames(df)
plot(df)
plot(df$y_pred)
plot(df$LifeExp)
rownames(df)
y_pred <- predict(regressor,newdata = dataset)
# see the predidcted values and actual values and compare
df <- data.frame(cbind(y_pred, dataset[dependent_var]))
colnames(df)
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(df), lab=rownames(df))
axis(2, las=1, at=4*0:g_range[2])
# Create box around plot
box()
g_range[2]
axis(2, las=1, at=10*0:g_range[2])
y_pred <- predict(regressor,newdata = dataset)
# see the predidcted values and actual values and compare
df <- data.frame(cbind(y_pred, dataset[dependent_var]))
colnames(df)
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(df), lab=rownames(df))
axis(2, las=1, at=10*0:g_range[2])
# Create box around plot
box()
axis(1, at=1:length(df), lab=rownames(df))
length(df)
df
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=1, at=10*0:g_range[2])
# Create box around plot
box()
plot(df$y_pred)
plot(df$LifeExp)
g_range
df$y_pred
df$LifeExp
g_range
axis(2, las=10, at=10*0:g_range[2])
# see the predidcted values and actual values and compare
df <- data.frame(cbind(y_pred, dataset[dependent_var]))
colnames(df)
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=10, at=10*0:g_range[2])
axis(2, las=1, at=10*0:g_range[2])
axis(2, las=1, at=10*10:g_range[2])
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=1, at=10*10:g_range[2])
axis(2, las=1, at=10*10:g_range[2])
# Create box around plot
box()
axis(2, las=1, at=10*0:g_range[2])
g_range[2]
axis(2, las=1, at=10*min(df$LifeExp):g_range[2])
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=1, at=10*min(df$LifeExp):g_range[2])
# Create box around plot
box()
axis(2, las=1, at=10*0:g_range[2])
axis(2, las=1, at=20*0:g_range[2])
axis(2, las=1, at=30*0:g_range[2])
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=1, at=30*0:g_range[2])
lines(df$LifeExp, type="o", pch=22, lty=2, col="red")
# Label the x and y axes with dark green text
title(xlab="States", col.lab=rgb(0,0.5,0))
title(ylab="Life Expectancy", col.lab=rgb(0,0.5,0))
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:22, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=121:22, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:122, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:22, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:22, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=1.8,
col=c("blue","red"), pch=21:22, lty=1:2);
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:22, lty=2:2);
###
# Now since we have the best Linear Regression model
# Let's apply that and do predictions.
###
lm_formula <- plt_lm_formula[which(plt_adjR_squares == max(plt_adjR_squares))]
regressor <- lm(formula = lm_formula, data = dataset)
summary(regressor)
y_pred <- predict(regressor,newdata = dataset)
# see the predidcted values and actual values and compare
df <- data.frame(cbind(y_pred, dataset[dependent_var]))
colnames(df)
# Visualization of predicted values vs actual values
g_range <- range(0, df$y_pred, df$LifeExp)
plot(df$y_pred, type="o", col="blue", ylim=g_range,
axes=FALSE, ann=FALSE)
axis(1, at=1:length(rownames(df)), lab=rownames(df))
axis(2, las=1, at=30*0:g_range[2])
# Create box around plot
box()
lines(df$LifeExp, type="o", pch=22, lty=2, col="red")
# Create a title with a red, bold/italic font
title(main="Autos", col.main="red", font.main=4)
# Label the x and y axes with dark green text
title(xlab="States", col.lab=rgb(0,0.5,0))
title(ylab="Life Expectancy", col.lab=rgb(0,0.5,0))
# Create a title with a red, bold/italic font
title(main="Predicted vs Actuals", col.main="red", font.main=4)
# Create box around plot
box()
lines(df$LifeExp, type="o", pch=22, lty=2, col="red")
# Create a title with a red, bold/italic font
title(main="Predicted vs Actuals", col.main="red", font.main=4)
# Label the x and y axes with dark green text
title(xlab="States", col.lab=rgb(0,0.5,0))
title(ylab="Life Expectancy", col.lab=rgb(0,0.5,0))
# Create a legend at (1, g_range[2]) that is slightly smaller
# (cex) and uses the same line colors and points used by
# the actual plots
legend(1, g_range[2], c("Predicted","Actuals"), cex=0.8,
col=c("blue","red"), pch=21:22, lty=2:2);
leg.txt <- c("Setosa     Petals", "Setosa     Sepals",
"Versicolor Petals", "Versicolor Sepals")
y.leg <- c(4.5, 3, 2.1, 1.4, .7)
cexv  <- c(1.2, 1, 4/5, 2/3, 1/2)
matplot(c(1, 8), c(0, 4.5), type = "n", xlab = "Length", ylab = "Width",
main = "Petal and Sepal Dimensions in Iris Blossoms")
for (i in seq(cexv)) {
text  (1, y.leg[i] - 0.1, paste("cex=", formatC(cexv[i])), cex = 0.8, adj = 0)
legend(3, y.leg[i], leg.txt, pch = "sSvV", col = c(1, 3), cex = cexv[i])
}
### ------------------------------------------------------------
## Run the example in '?matplot' or the following:
leg.txt <- c("Setosa     Petals", "Setosa     Sepals",
"Versicolor Petals", "Versicolor Sepals")
y.leg <- c(4.5, 3, 2.1, 1.4, .7)
cexv  <- c(1.2, 1, 4/5, 2/3, 1/2)
matplot(c(1, 8), c(0, 4.5), type = "n", xlab = "Length", ylab = "Width",
main = "Petal and Sepal Dimensions in Iris Blossoms")
?matplot
### ------------------------------------------------------------
## Run the example in '?matplot' or the following:
leg.txt <- c("Setosa     Petals", "Setosa     Sepals",
"Versicolor Petals", "Versicolor Sepals")
y.leg <- c(4.5, 3, 2.1, 1.4, .7)
cexv  <- c(1.2, 1, 4/5, 2/3, 1/2)
matplot(c(1, 8), c(0, 4.5), type = "n", xlab = "Length", ylab = "Width",
main = "Petal and Sepal Dimensions in Iris Blossoms")
# Plot the Adjusted R-squared
plot(plt_adjR_squares, type="b", col="blue",
ylim = range(min(plt_adjR_squares) - 0.05, 0.95),
axes = FALSE, ann= FALSE)
# Make x axis using Mon-Fri labels
axis(1, at=1:length(plt_adjR_squares), lab=F)
text(axTicks(1), y= 0, srt=45, adj=1,
labels=plt_adjR_squares,
xpd=T, cex=1)
# Plot y axis with smaller horizontal labels
axis(2, las=1, cex.axis=0.8)
# Create box around plot
box()
# Create a title with a red, bold/italic font
title(main="Linear Regression (Best model)", col.main="red", font.main=4)
# Label the x and y axes with dark green text
title(xlab="Formula", col.lab=rgb(0,0.5,0))
title(ylab="R-Squared", col.lab=rgb(0,0.5,0))
setwd("D:/ujjwal/Tutorial/Udemy/Machine Learning A-Z Template Folder/Part 5 - Association Rule Learning/Section 28 - Apriori/Practice")
install.packages('arules')
